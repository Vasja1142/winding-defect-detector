# Winding Defect Detector

## Обзор Проекта
Этот проект представляет собой систему для обнаружения дефектов обмотки с использованием модели YOLO (You Only Look Once). Он включает в себя пайплайн для подготовки данных, скрипты для обучения и дообучения модели, а также интеграцию с MLflow для отслеживания экспериментов.

## Особенности
-   **Обнаружение Дефектов:** Использование YOLOv12 для точного обнаружения дефектов на изображениях обмоток.
-   **Пайплайн Подготовки Данных:** Автоматизированная обработка необработанных видеофайлов в размеченные кадры, готовые для обучения.
-   **Интеграция с MLflow:** Отслеживание параметров обучения, метрик и артефактов (моделей, графиков) с помощью MLflow.
-   **Dockerized Environment:** Все компоненты упакованы в Docker-контейнеры для легкого развертывания и воспроизводимости.

## Структура Проекта
```
.
├── .dockerignore
├── .gitignore
├── config.yaml               # Файл конфигурации датасета для YOLO
├── docker-compose.yml        # Конфигурация Docker Compose для сервисов (детектор, MLflow)
├── Dockerfile                # Dockerfile для сборки образа детектора
├── README.md                 # Этот файл
├── requirements.txt          # Зависимости Python
├── data/                     # Директория для данных
│   ├── 00_pretrained/        # Предобученные модели
│   ├── 01_raw/               # Исходные необработанные видео
│   ├── 02_processed/         # Обработанные кадры из видео
│   ├── 03_annotations_raw/   # Исходные аннотации
│   ├── 04_datasets/          # Подготовленные датасеты для обучения (изображения + метки)
│   └── 05_runs/              # Результаты запусков обучения (логи, веса)
└── src/                      # Исходный код проекта
    ├── create_labeled_video.py
    ├── create_verification_set.py
    ├── data_processing.py
    ├── inference_server.py
    ├── prepare_dataset.py
    ├── run_data_prep.py      # Скрипт для запуска пайплайна подготовки данных
    ├── sanitize_filenames.py
    ├── train.py              # Скрипт для обучения модели YOLO с MLflow
    └── utils/                # Вспомогательные утилиты
        ├── augment_offline.py
        ├── merge_classes.py
        ├── remove_duplicate_boxes.py
        ├── smart_merge.py
        └── yolo_to_cvat_xml.py
```

## Настройка и Запуск

### Требования
-   Docker и Docker Compose установлены.
-   NVIDIA GPU с установленными драйверами (для использования GPU в Docker).

### Шаги по Настройке
1.  **Клонируйте репозиторий:**
    ```bash
    git clone <ваш_репозиторий_здесь>
    cd winding-defect-detector
    ```

2.  **Подготовьте данные:**
    Поместите необработанные видеофайлы в директорию `data/01_raw`.
    Убедитесь, что у вас есть размеченные данные в формате YOLO в `data/04_datasets`. Если их нет, вам нужно будет запустить пайплайн подготовки данных и аннотирования.

3.  **Соберите Docker-образы:**
    ```bash
    docker compose build
    ```

4.  **Запустите сервисы Docker Compose:**
    Это запус��ит контейнеры `detector` (для обучения/инференса) и `mlflow-server` (для отслеживания экспериментов).
    ```bash
    docker compose up -d
    ```
    MLflow UI будет доступен по адресу `http://localhost:5001`.

## Использование

### 1. Подготовка Данных (если необходимо)
Если у вас есть только необработанные видео и нет подготовленных датасетов в `data/04_datasets`, вы можете использовать скрипт `run_data_prep.py` для извлечения кадров.
**Важно:** Этот скрипт извлекает кадры в `data/02_processed/frames`. После этого вам потребуется вручную аннотировать эти кадры и затем использовать другие скрипты (например, `prepare_dataset.py` или `smart_merge.py`) для создания датасета в `data/04_datasets` в формате YOLO.

Для запуска извлечения кадров:
```bash
docker compose exec detector python3 src/run_data_prep.py
```

### 2. Обучение Модели
Для обучения или дообучения модели используйте скрипт `train.py`.
Вы можете указать путь к предобученной модели (`yolo12n.pt`), количество эпох, размер батча и размер изображения.

Пример запуска обучения на 20 эпох с моделью `yolo12n.pt`, разрешением 640 и батчем 64:
```bash
docker compose exec detector python3 src/train.py --model yolo12n.pt --epochs 20 --imgsz 640 --batch 64
```
Результаты обучения (логи, метрики, веса модели) будут автоматически логироваться в MLflow.

### 3. Инференс (Вывод)
(Инструкции по инференсу будут добавлены позже, если есть соответствующий скрипт, например, `inference_server.py`).

## MLflow
MLflow Tracking Server доступен по адресу `http://localhost:5001`. Здесь вы можете просматривать все свои эксперименты, сравнивать запуски, анализировать метрики и загружать артефакты (например, обученные модели).

## Конфигурация
Файл `config.yaml` содержит пути к данным и информацию о классах для обучения YOLO. Убедитесь, что пути `train` и `val` в этом файле соответствуют структуре вашего датасета в `data/04_datasets`.
```yaml
path: /app/data/04_datasets
train: train/images
val: valid/images
names:
  0: row_gap
  1: defect
```
